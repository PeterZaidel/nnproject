{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pycocotools.coco import COCO\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "\n",
    "import operator\n",
    "import skimage.io as io\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import pickle\n",
    "\n",
    "sys.path.append('/mnt/disk/p.zaydel_OLOLO/Mankevich/')\n",
    "sys.path.append('/mnt/disk/p.zaydel_OLOLO/Mankevich/coco-caption/')\n",
    "from pycocoevalcap.tokenizer.ptbtokenizer import PTBTokenizer\n",
    "from pycocoevalcap.bleu.bleu import Bleu\n",
    "import string\n",
    "\n",
    "from exceptions import SyntaxError\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDir='/mnt/disk/p.zaydel_OLOLO/Mankevich/coco_dataset/'\n",
    "imagesDirTrain = '{}train2017'.format(dataDir)\n",
    "imagesDirVal = '{}val2017'.format(dataDir)\n",
    "\n",
    "annTrainFile = '{}annotations/captions_train2017.json'.format(dataDir)\n",
    "annValFile = '{}annotations/captions_val2017.json'.format(dataDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(s):\n",
    "    s = s.lower()\n",
    "    for t in string.punctuation: \n",
    "        s = s.replace(t, ' ')\n",
    "    return s\n",
    "\n",
    "\n",
    "def numpy2image(img_numpy):\n",
    "    if img_numpy.dtype == np.dtype('float64'):\n",
    "        img_numpy = (img_numpy*255).astype('uint8')\n",
    "    return Image.fromarray(img_numpy)\n",
    "\n",
    "\n",
    "class MSCOCODataset(Dataset):\n",
    "    \"\"\"MSCOCO Dataset\"\"\"\n",
    "\n",
    "    def __init__(self, annFile, imagesDir, transform=None):\n",
    "        self.coco = COCO(annFile)\n",
    "        self.imagesDir = imagesDir\n",
    "        self.imageids = self.coco.getImgIds()\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.coco.dataset['images'])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        imid = self.imageids[idx]\n",
    "        img_data = self.coco.loadImgs([imid])[0]\n",
    "        \n",
    "        img_file_name = '{}/{}'.format(self.imagesDir, img_data['file_name'])\n",
    "        image = io.imread(img_file_name)\n",
    "        \n",
    "        if len(image.shape) != 3:\n",
    "            return self.__getitem__(0)\n",
    "        \n",
    "        image = numpy2image(image)\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        sample = {'image': image, 'id': imid}\n",
    "            \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN:\n",
    "    def __init__(self, k, coco, model, pretrained=False):\n",
    "        '''\n",
    "        k: int, count of nearest neighborhood\n",
    "        coco: COCO(annTrainFile), annTrainFile - file with annotations of train dataset\n",
    "        model: torchvision.models, pretrained classifier model\n",
    "        pretrained: bool, if True load converted images for files\n",
    "        '''\n",
    "        self.k = k\n",
    "        self.coco = coco\n",
    "        self.cnn = model\n",
    "        self.mertric = Bleu()\n",
    "        self.pretrained = pretrained\n",
    "       \n",
    "    def images2vec(self, loader, max_batch_iter):\n",
    "        '''\n",
    "        Convert each image in vector(torch array)\n",
    "        loader: Dataloader(MSCOCODataset)       \n",
    "        return: (torch.array, torch.array)\n",
    "        '''\n",
    "        if len(loader) == 0:\n",
    "            raise SyntaxError('\\rError: empty input in method images2vec()')\n",
    "        \n",
    "        res = None\n",
    "        res_ids = None\n",
    "        for i, item in tqdm(enumerate(loader)):\n",
    "            \n",
    "            X = Variable(item['image'].type(torch.cuda.FloatTensor))\n",
    "            ids = item['id']\n",
    "            \n",
    "            vec = self.cnn.forward(X).data.cpu()\n",
    "            \n",
    "            if res is None:\n",
    "                res = vec\n",
    "                res_ids = ids\n",
    "            else:\n",
    "                res = torch.cat((res, vec), 0)\n",
    "                res_ids = torch.cat((res_ids, ids), 0)\n",
    "                \n",
    "            if i == max_batch_iter - 1:\n",
    "                break\n",
    "                \n",
    "        return res, res_ids\n",
    "            \n",
    "    def predict(self, train_loader, test_loader, max_batch_iter=10):\n",
    "        '''\n",
    "        Create pretrained dataset for algorithm\n",
    "        train_loader: Dataloader(MSCOCODataset)\n",
    "        test_loader: Dataloader(MSCOCODataset)\n",
    "        return: dict, key is <mscoco_id> of each image, value is annotation\n",
    "        '''\n",
    "        if len(train_loader) == 0 or len(test_loader) == 0:\n",
    "            raise SyntaxError('\\rError: empty input in method predict()')\n",
    "        \n",
    "        if self.pretrained:\n",
    "            train_image = torch.load('../lstm/train_image_resnet.pth').numpy()\n",
    "            train_image_id = torch.load('../lstm/train_image_ids_resnet.pth').numpy()\n",
    "            test_image = torch.load('../lstm/test_image_resnet.pth').numpy()\n",
    "            test_image_id = torch.load('../lstm/test_image_ids_resnet.pth').numpy()\n",
    "        else:\n",
    "            train_image, train_image_id = self.images2vec(train_loader, max_batch_iter)\n",
    "            test_image, test_image_id = self.images2vec(test_loader, max_batch_iter)\n",
    "            \n",
    "            print \"Congratulations! All images converted\"\n",
    "            \n",
    "            torch.save(train_image, 'train_image.pth')\n",
    "            torch.save(train_image_id, 'train_image_id.pth')\n",
    "            torch.save(test_image, 'test_image.pth')\n",
    "            torch.save(test_image_id, 'test_image_id.pth')\n",
    "        \n",
    "        pairs = pairwise_distances(test_image, train_image)                \n",
    "        nearest_ids = np.zeros((test_image.shape[0], self.k))\n",
    "        \n",
    "        for i in range(self.k):\n",
    "            ids = np.argmin(pairs, 1)\n",
    "            nearest_ids[:, i] = ids[:]\n",
    "            for i, idx in enumerate(ids):\n",
    "                pairs[i, idx] = 10**3\n",
    "        nearest_ids = nearest_ids.astype(np.int)\n",
    "        \n",
    "        res = {}\n",
    "        for it in tqdm(range(nearest_ids.shape[0])):\n",
    "            anns_ids = self.coco.getAnnIds(imgIds=train_image_id[nearest_ids[it]])\n",
    "            anns = self.coco.loadAnns(anns_ids)\n",
    "            anns = [ann['caption'] for ann in anns]\n",
    "            dist_sim = np.zeros((len(anns), len(anns)))\n",
    "            \n",
    "            for i in range(len(anns)):\n",
    "                for j in range(i + 1, len(anns)):\n",
    "                    \n",
    "                    ref = {1: [tokenize(anns[i])]}\n",
    "                    cand = {1: [tokenize(anns[j])]}\n",
    "                    \n",
    "                    dist_sim[i][j] = self.mertric.compute_score(ref, cand)[1][3][0]\n",
    "                    dist_sim[j][i] = self.mertric.compute_score(cand, ref)[1][3][0]\n",
    "                    \n",
    "            dist_sim_sum = dist_sim.sum(0)\n",
    "            res[test_image_id[it]] = anns[np.argmax(dist_sim_sum)]\n",
    "            \n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.Resize((224, 224)), \n",
    "                                             transforms.ToTensor(), \n",
    "                                             transforms.Normalize(\n",
    "                                                 mean=[0.485, 0.456, 0.406],\n",
    "                                                 std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "train_dataset = MSCOCODataset(annTrainFile, imagesDirTrain, transform)\n",
    "test_dataset = MSCOCODataset(annValFile, imagesDirVal, transform)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=128)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32)\n",
    "\n",
    "# torch.cuda.set_device(2)\n",
    "#model = models.vgg16(pretrained=True)\n",
    "#model.classifier = torch.nn.Sequential(torch.nn.Sequential(*(model.classifier[i] for i in range(4))))\n",
    "#model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = KNN(20, COCO(annTrainFile), None, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "res = m.predict(train_dataloader, test_dataloader, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To check results start from here\n",
    "res = pickle.load(open('./res_resnet.p', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_coco = COCO(annValFile)\n",
    "for i, key in enumerate(res.keys()):\n",
    "    if key != 326248:\n",
    "        continue\n",
    "    img_data = val_coco.loadImgs([key])[0]\n",
    "    img_file_name = '{}/{}'.format(imagesDirVal, img_data['file_name'])\n",
    "    image = io.imread(img_file_name)\n",
    "    print image.shape\n",
    "    plt.imshow(image)\n",
    "    print '\\nKNN: {}\\n'.format(res[key]) \n",
    "    \n",
    "    anns_ids = val_coco.getAnnIds([key])\n",
    "    anns = val_coco.loadAnns(anns_ids)\n",
    "    anns = [ann['caption'] for ann in anns]\n",
    "    print anns\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
